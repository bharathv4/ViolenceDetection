{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import util\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "def FrameCapture(path,skipfactor=3): \n",
    "    #clearing extracted frames\n",
    "    files = glob.glob('extractedframes/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "        \n",
    "    # Path to video file \n",
    "    vidObj = cv2.VideoCapture(path) \n",
    "    fps = vidObj.get(cv2.CAP_PROP_FPS)\n",
    "    print(fps)\n",
    "    vidObj.set(cv2.CAP_PROP_FPS, 30)\n",
    "    fps = vidObj.get(cv2.CAP_PROP_FPS)\n",
    "    print(fps)\n",
    "    # Used as counter variable \n",
    "    count = 0\n",
    "    ind = 0\n",
    "  \n",
    "    # checks whether frames were extracted \n",
    "    success = 1\n",
    "    listOfImages = []\n",
    "    while success: \n",
    "  \n",
    "        # vidObj object calls read \n",
    "        # function extract frames \n",
    "        success, image = vidObj.read()\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Saves the frames with frame-count \n",
    "        if(count%skipfactor==0):\n",
    "            listOfImages.append(image)\n",
    "            \n",
    "            #cv2.imwrite(\"extractedframes/frame%d.jpg\" %ind, image)\n",
    "            #cv2.imshow('frame%d.jpg'%ind,image)\n",
    "            \n",
    "            ind += 1\n",
    "        count += 1\n",
    "        type(image)\n",
    "    return listOfImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListGrayscaleFrameArrays(listOfFrames):\n",
    "    listOfFrameArray=[]\n",
    "    listOfFrames.pop()\n",
    "    \n",
    "    for ind,frame  in enumerate(listOfFrames):\n",
    "        #converts RBG image to Gray scale and returns as numpy 2D array\n",
    "        ff= frame.copy()\n",
    "        gray = cv2.cvtColor(ff, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "#         print(gray.shape)\n",
    "#         scale_percent = 60 # percent of original size\n",
    "#         width = int(1000)\n",
    "#         height = int(1000)\n",
    "#         dim = (width, height)\n",
    "#         # resize image\n",
    "#         resized = cv2.resize(gray, dim, interpolation = cv2.INTER_AREA)\n",
    "        cv2.imwrite(\"grayframes/frame%d.jpg\" %ind, gray)\n",
    "        #using PIL\n",
    "        #grayscalearray = np.array(Image.fromarray(frame).convert('L'))\n",
    "        grayscalearray = np.array(gray)\n",
    "        \n",
    "        listOfFrameArray.append(grayscalearray)\n",
    "        \n",
    "    return listOfFrameArray\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def StoreFrames(path,skipfactor=2):\n",
    "    #extracted features stores all gray frames of a  video individually for further processing\n",
    "    #clear extracted frames folder first\n",
    "    files = glob.glob('extractedframes/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    FrameCapture(path,skipfactor)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A  video is converted to a numpy array\n",
    "def ConvertVideoToGrayscaleArray(path):\n",
    "    listofImages = FrameCapture(path,2)\n",
    "\n",
    "    GrayScaleList= ListGrayscaleFrameArrays(listofImages)\n",
    "    \n",
    "    ArrayofGrayScaleArray = np.array(GrayScaleList)\n",
    "    \n",
    "    #print(ArrayofGrayScaleArray.shape)\n",
    "    return ArrayofGrayScaleArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movementfiltering\n",
    "\n",
    "#stores binarized list of frames in jpg format \n",
    "def BinarizeGrayscaleArray(ArrayofGrayScaleArray,path,threshold=120):\n",
    "    files = glob.glob('binaryframes/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    for i in range(1,ArrayofGrayScaleArray.shape[0]):\n",
    "        binaryImage=abs(ArrayofGrayScaleArray[i]-ArrayofGrayScaleArray[i-1])\n",
    "        data = Image.fromarray(binaryImage)\n",
    "        data.save('temporalderivatives/'+'frame%d.jpg'%i)\n",
    "        #Binarization\n",
    "        binaryImage[binaryImage > threshold] = 255\n",
    "        binaryImage[binaryImage <= threshold] = 0 \n",
    "        \n",
    "        data = Image.fromarray(binaryImage) \n",
    "        data.save(path+'/'+'frame%d.jpg'%i)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DELL\\\\ViolenceDetection'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erodeBinaryFrames(binaryframespath,erodedframespath):\n",
    "    erosionkernel = np.array([\n",
    "        [0,0,1,0],\n",
    "        [0,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [0,1,1,0],\n",
    "        \n",
    "        \n",
    "        \n",
    "    ],np.uint8)\n",
    "    \n",
    "#     [0,0,0,1,1,0,0,0],\n",
    "#     [0,0,1,1,1,1,0,0],\n",
    "#     [0,1,1,1,1,1,1,0],\n",
    "#     [1,1,1,1,1,1,1,1],\n",
    "#     [1,1,1,1,1,1,1,1],\n",
    "#     [0,1,1,1,1,1,1,0],\n",
    "#     [0,0,1,1,1,1,0,0],\n",
    "#     [0,0,0,1,1,0,0,0]\n",
    "    dilationkernel = np.array([\n",
    "        [0,0,0,1,1,0,0,0],\n",
    "        [0,0,1,1,1,1,0,0],\n",
    "        [0,1,1,1,1,1,1,0],\n",
    "        [1,1,1,1,1,1,1,1],\n",
    "        [1,1,1,1,1,1,1,1],\n",
    "        [0,1,1,1,1,1,1,0],\n",
    "        [0,0,1,1,1,1,0,0],\n",
    "        [0,0,0,1,1,0,0,0]\n",
    "    ],np.uint8)\n",
    "    \n",
    "\n",
    "    # Taking a matrix of size 5 as the kernel \n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    kernel[0][0]=0\n",
    "    kernel[0][2]=0\n",
    "    kernel[2][0]=0\n",
    "    kernel[2][2]=0\n",
    "    print(kernel)\n",
    "    # The first parameter is the original image, \n",
    "    # kernel is the matrix with which image is  \n",
    "    # convolved and third parameter is the number  \n",
    "    # of iterations, which will determine how much  \n",
    "    # you want to erode/dilate a given image.\n",
    "    files = glob.glob(erodedframespath+'/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    files = glob.glob(binaryframespath+'/*')\n",
    "    for ind,f in enumerate(files):\n",
    "        img = cv2.imread(f, 0) \n",
    "        \n",
    "        img = cv2.erode(img, erosionkernel, iterations=3)\n",
    "        img = cv2.dilate(img, kernel, iterations=2)\n",
    "        img = cv2.erode(img, erosionkernel, iterations=2) \n",
    "        #img = cv2.dilate(img, kernel, iterations=1)\n",
    "        #img = cv2.erode(img, erosionkernel, iterations=1) \n",
    "        #img = cv2.dilate(img, kernel, iterations=1)\n",
    "        #img = cv2.erode(img, erosionkernel, iterations=1) \n",
    "        \n",
    "        cv2.imwrite(erodedframespath+\"/frame%d.jpg\" %ind,img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n",
      "25.0\n",
      "[[0 1 0]\n",
      " [1 1 1]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "def preprocess(videopath):\n",
    "    #A  video is converted to a numpy array\n",
    "    ArrayofGrayScaleArray= ConvertVideoToGrayscaleArray(videopath)\n",
    "    BinarizeGrayscaleArray(ArrayofGrayScaleArray,'binaryframes')\n",
    "    erodeBinaryFrames(\"binaryframes\",\"morphologicallyopenedframes\")\n",
    "#upto morphological opening\n",
    "preprocess('samplefights/newfi30.avi')\n",
    "#preprocess('samplefights/fi1_xvid.avi')\n",
    "\n",
    "#preprocess('samplefights/51.mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "cells = [15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239, 255]\n",
    "\n",
    "\n",
    "def gen_neighbors(x, y):\n",
    "    neighbor_1 = [[x - 8, y + 8], [x - 7, y + 8], [x - 6, y + 8], [x - 5, y + 8],\n",
    "          [x - 8, y + 7], [x - 7, y + 7], [x - 6, y + 7], [x - 5, y + 7],\n",
    "          [x - 8, y + 6], [x - 7, y + 6], [x - 6, y + 6], [x - 5, y + 6],\n",
    "          [x - 8, y + 5], [x - 7, y + 5], [x - 6, y + 5], [x - 5, y + 5]]\n",
    "\n",
    "    neighbor_2 = [[x - 4, y + 8], [x - 3, y + 8], [x - 2, y + 8], [x - 1, y + 8],\n",
    "          [x - 4, y + 7], [x - 3, y + 7], [x - 2, y + 7], [x - 1, y + 7],\n",
    "          [x - 4, y + 6], [x - 3, y + 6], [x - 2, y + 6], [x - 1, y + 6],\n",
    "          [x - 4, y + 5], [x - 3, y + 5], [x - 2, y + 5], [x - 1, y + 5]]\n",
    "\n",
    "    neighbor_3 = [[x + 1, y + 8], [x + 2, y + 8], [x + 3, y + 8], [x + 4, y + 8],\n",
    "          [x + 1, y + 7], [x + 2, y + 7], [x + 3, y + 7], [x + 4, y + 7],\n",
    "          [x + 1, y + 6], [x + 2, y + 6], [x + 3, y + 6], [x + 4, y + 6],\n",
    "          [x + 1, y + 5], [x + 2, y + 5], [x + 3, y + 5], [x +  4, y + 5]]\n",
    "\n",
    "    neighbor_4 = [[x + 5, y + 8], [x + 6, y + 8], [x + 7, y + 8], [x + 8, y + 8],\n",
    "          [x + 5, y + 7], [x + 6, y + 7], [x + 7, y + 7], [x + 8, y + 7],\n",
    "          [x + 5, y + 6], [x + 6, y + 6], [x + 7, y + 6], [x + 8, y + 6],\n",
    "          [x + 5, y + 5], [x + 6, y + 5], [x + 7, y + 5], [x + 8, y + 5]]\n",
    "\n",
    "    neighbor_5 = [[x - 8, y + 4], [x - 7, y + 4], [x - 6, y + 4], [x - 5, y + 4],\n",
    "          [x - 8, y + 3], [x - 7, y + 3], [x - 6, y + 3], [x - 5, y + 3],\n",
    "          [x - 8, y + 2], [x - 7, y + 2], [x - 6, y + 2], [x - 5, y + 2],\n",
    "          [x - 8, y + 1], [x - 7, y + 1], [x - 6, y + 1], [x - 5, y + 1]]\n",
    "\n",
    "    neighbor_6 = [[x - 4, y + 4], [x - 3, y + 4], [x - 2, y + 4], [x - 1, y + 4],\n",
    "          [x - 4, y + 3], [x - 3, y + 3], [x - 2, y + 3], [x - 1, y + 3],\n",
    "          [x - 4, y + 2], [x - 3, y + 2], [x - 2, y + 2], [x - 1, y + 2],\n",
    "          [x - 4, y + 1], [x - 3, y + 1], [x - 2, y + 1], [x - 1, y + 1]]\n",
    "\n",
    "    neighbor_7 = [[x + 1, y + 4], [x + 2, y + 4], [x + 3, y + 4], [x + 4, y + 4],\n",
    "          [x + 1, y + 3], [x + 2, y + 3], [x + 3, y + 3], [x + 4, y + 3],\n",
    "          [x + 1, y + 2], [x + 2, y + 2], [x + 3, y + 2], [x + 4, y + 2],\n",
    "          [x + 1, y + 1], [x + 2, y + 1], [x + 3, y + 1], [x + 4, y + 1]]\n",
    "\n",
    "    neighbor_8 = [[x + 5, y + 4], [x + 6, y + 4], [x + 7, y + 4], [x + 8, y + 4],\n",
    "          [x + 5, y + 3], [x + 6, y + 3], [x + 7, y + 3], [x + 8, y + 3],\n",
    "          [x + 5, y + 2], [x + 6, y + 2], [x + 7, y + 2], [x + 8, y + 2],\n",
    "          [x + 5, y + 1], [x + 6, y + 1], [x + 7, y + 1], [x + 8, y + 1]]\n",
    "\n",
    "    neighbor_9 = [[x - 8, y - 4], [x - 7, y - 4], [x - 6, y - 4], [x - 5, y - 4],\n",
    "          [x - 8, y - 3], [x - 7, y - 3], [x - 6, y - 3], [x - 5, y - 3],\n",
    "          [x - 8, y - 2], [x - 7, y - 2], [x - 6, y - 2], [x - 5, y - 2],\n",
    "          [x - 8, y - 1], [x - 7, y - 1], [x - 6, y - 1], [x - 5, y - 1]]\n",
    "\n",
    "    neighbor_10 = [[x - 4, y - 4], [x - 3, y - 4], [x - 2, y - 4], [x - 1, y - 4],\n",
    "           [x - 4, y - 3], [x - 3, y - 3], [x - 2, y - 3], [x - 1, y - 3],\n",
    "           [x - 4, y - 2], [x - 3, y - 2], [x - 2, y - 2], [x - 1, y - 2],\n",
    "           [x - 4, y - 1], [x - 3, y - 1], [x - 2, y - 1], [x - 1, y - 1]]\n",
    "\n",
    "    neighbor_11 = [[x + 1, y - 4], [x + 2, y - 4], [x + 3, y - 4], [x + 4, y - 4],\n",
    "           [x + 1, y - 3], [x + 2, y - 3], [x + 3, y - 3], [x + 4, y - 3],\n",
    "           [x + 1, y - 2], [x + 2, y - 2], [x + 3, y - 2], [x + 4, y - 2],\n",
    "           [x + 1, y - 1], [x + 2, y - 1], [x + 3, y - 1], [x + 4, y - 1]]\n",
    "\n",
    "    neighbor_12 = [[x + 5, y - 4], [x + 6, y - 4], [x + 7, y - 4], [x + 8, y - 4],\n",
    "           [x + 5, y - 3], [x + 6, y - 3], [x + 7, y - 3], [x + 8, y - 3],\n",
    "           [x + 5, y - 2], [x + 6, y - 2], [x + 7, y - 2], [x + 8, y - 2],\n",
    "           [x + 5, y - 1], [x + 6, y - 1], [x + 7, y - 1], [x + 8, y - 1]]\n",
    "\n",
    "    neighbor_13 = [[x - 8, y - 8], [x - 7, y - 8], [x - 6, y - 8], [x - 5, y - 8],\n",
    "           [x - 8, y - 7], [x - 7, y - 7], [x - 6, y - 7], [x - 5, y - 7],\n",
    "           [x - 8, y - 6], [x - 7, y - 6], [x - 6, y - 6], [x - 5, y - 6],\n",
    "           [x - 8, y - 5], [x - 7, y - 5], [x - 6, y - 5], [x - 5, y - 5]]\n",
    "\n",
    "    neighbor_14 = [[x - 4, y - 8], [x - 3, y - 8], [x - 2, y - 8], [x - 1, y - 8],\n",
    "           [x - 4, y - 7], [x - 3, y - 7], [x - 2, y - 7], [x - 1, y - 7],\n",
    "           [x - 4, y - 6], [x - 3, y - 6], [x - 2, y - 6], [x - 1, y - 6],\n",
    "           [x - 4, y - 5], [x - 3, y - 5], [x - 2, y - 5], [x - 1, y - 5]]\n",
    "\n",
    "    neighbor_15 = [[x + 1, y - 8], [x + 2, y - 8], [x + 3, y - 8], [x + 4, y - 8],\n",
    "           [x + 1, y - 7], [x + 2, y - 7], [x + 3, y - 7], [x + 4, y - 7],\n",
    "           [x + 1, y - 6], [x + 2, y - 6], [x + 3, y - 6], [x + 4, y - 6],\n",
    "           [x + 1, y - 5], [x + 2, y - 5], [x + 3, y - 5], [x + 4, y - 5]]\n",
    "\n",
    "    neighbor_16 = [[x + 5, y - 8], [x + 6, y - 8], [x + 7, y - 8], [x + 8, y - 8],\n",
    "           [x + 5, y - 7], [x + 6, y - 7], [x + 7, y - 7], [x + 8, y - 7],\n",
    "           [x + 5, y - 6], [x + 6, y - 6], [x + 7, y - 6], [x + 8, y - 6],\n",
    "           [x + 5, y - 5], [x + 6, y - 5], [x + 7, y - 5], [x + 8, y - 5]]\n",
    "\n",
    "    neighbors = neighbor_1+neighbor_2+neighbor_3+neighbor_4+neighbor_5+neighbor_6+neighbor_7+neighbor_8+ \\\n",
    "                neighbor_9+neighbor_10+neighbor_11+neighbor_12+neighbor_13+neighbor_14+neighbor_15+neighbor_16\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "def gen_arc_histogram(direction, histogram):\n",
    "    if direction > (2*math.pi)/3 and direction <= math.pi/3:\n",
    "        histogram[0]+=1\n",
    "    elif direction > math.pi/3 and direction <= math.pi/6:\n",
    "        histogram[1]+=1\n",
    "    elif direction > math.pi/6 and direction <= (11*math.pi)/6:\n",
    "        histogram[2]+=1\n",
    "    elif direction > (11*math.pi)/6 and direction <= (5*math.pi)/3:\n",
    "        histogram[3]+=1\n",
    "    elif direction > (5*math.pi)/3 and direction <= (4*math.pi)/3:\n",
    "        histogram[4]+=1\n",
    "    elif direction > (4*math.pi)/3 and direction <= (5*math.pi)/4:\n",
    "        histogram[5]+=1\n",
    "    elif direction > (5*math.pi)/4 and direction <= math.pi:\n",
    "        histogram[6]+=1\n",
    "    elif direction > math.pi and direction <= (2*math.pi)/3:\n",
    "        histogram[7]+=1\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIFT\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import util\n",
    "import os\n",
    "import random\n",
    "\n",
    "# params for ShimTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# params for Lucas Kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "\n",
    "def capture_frame(video_path, i):\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    cap.set(1, i)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    return ret, frame\n",
    "\n",
    "\n",
    "def count_frames(video_path):\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def gen_sift_features(frame):\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(frame, None)\n",
    "\n",
    "    return keypoints, descriptors\n",
    "\n",
    "\n",
    "def keypoints_to_coordinates(keypoints):\n",
    "    keypoints_xy = []\n",
    "\n",
    "    for kp in keypoints:\n",
    "        keypoints_xy.append([kp.pt[0], kp.pt[1]])\n",
    "\n",
    "    return keypoints_xy\n",
    "\n",
    "\n",
    "def has_sufficient_motion(keypoints_xy, keypoints, descriptors, p1, lambd):\n",
    "    sm_keypoints_xy = []\n",
    "    sm_keypoints = []\n",
    "    sm_descriptors = []\n",
    "\n",
    "    for i in range(len(keypoints)):\n",
    "        distance_x = keypoints_xy[i].T[0] - p1[i].T[0]\n",
    "        distance_y = keypoints_xy[i].T[1] - p1[i].T[1]\n",
    "\n",
    "        if distance_x > lambd or distance_y > lambd:\n",
    "            sm_keypoints_xy.append([int(keypoints_xy[i].T[0]), int(keypoints_xy[i].T[1])])\n",
    "            sm_keypoints.append(keypoints[i])\n",
    "            sm_descriptors.append(descriptors[i])\n",
    "\n",
    "    return sm_keypoints_xy, sm_keypoints, sm_descriptors\n",
    "\n",
    "\n",
    "def gen_hof(x, y, frame, next_frame):\n",
    "    hof = []\n",
    "    histogram = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    neighbors = gen_neighbors(x, y)\n",
    "    neighbors = np.float32(np.array(neighbors)[:, np.newaxis, :])\n",
    "    p1, st, err = cv.calcOpticalFlowPyrLK(frame, next_frame, neighbors, None, **lk_params)\n",
    "\n",
    "    for i in range(len(p1)):\n",
    "        direction = np.arctan(p1[i].T[0]/p1[i].T[1])\n",
    "        histogram = gen_arc_histogram(direction, histogram)\n",
    "        if i in cells:\n",
    "            hof += histogram\n",
    "            histogram = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    return hof\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_mosift_features(video_path, lambd, interval, sample_size):\n",
    "#     frames = count_frames(video_path)\n",
    "#     mosift_descriptors = []\n",
    "\n",
    "#     for i in range(1, frames-1, interval):\n",
    "#         #try:\n",
    "#         ret, frame = capture_frame(video_path, i)\n",
    "#         ret, next_frame = capture_frame(video_path, i+1)\n",
    "#         print(type(frame))\n",
    "#         keypoints, descriptors = gen_sift_features(frame)\n",
    "#         keypoints_xy = keypoints_to_coordinates(keypoints)\n",
    "#         keypoints_xy = np.float32(np.array(keypoints_xy)[:, np.newaxis, :])\n",
    "#         p1, st, err = cv.calcOpticalFlowPyrLK(frame, next_frame, keypoints_xy, None, **lk_params)\n",
    "#         sm_keypoints_xy, sm_keypoints, sm_descriptors = has_sufficient_motion(keypoints_xy, keypoints, descriptors, p1, lambd)\n",
    "\n",
    "#         for j in range(len(sm_keypoints)):\n",
    "#             hof = np.array(gen_hof(sm_keypoints_xy[j][0], sm_keypoints_xy[j][1], frame, next_frame))\n",
    "#             mosift_descriptors.append(list(np.concatenate((sm_descriptors[j], hof))))\n",
    "#         #except:\n",
    "#             #print('Exception in '+video_path+', frame '+str(i))\n",
    "\n",
    "#     random_mosift_descriptors = random.sample(mosift_descriptors, k=int(len(mosift_descriptors)*sample_size))\n",
    "\n",
    "#     return random_mosift_descriptors\n",
    "\n",
    "\n",
    "# def run_feature_extractor(input_path, output_path, lambd, interval, sample_size):\n",
    "#     listing = os.listdir(input_path)\n",
    "#     progress_count = 0\n",
    "#     for video_name in listing:\n",
    "#         progress_count += 1\n",
    "#         print(\"# progress: \"+str(progress_count)+'/'+str(len(listing)))\n",
    "#         video_path = input_path+'/'+ video_name\n",
    "        \n",
    "#         df_mosift_features = pd.DataFrame(gen_mosift_features(video_path, lambd, interval, sample_size))\n",
    "#         print(df_mosift_features.shape)\n",
    "#         #df_mosift_features.to_csv(output_path+'/'+ video_name[:-4]+\".csv\", mode='a', header=False, index=False)\n",
    "\n",
    "# run_feature_extractor('siftvideo','siftoutput',0.9,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_mosift_features(morphopath, lambd, interval, sample_size):\n",
    "    files = glob.glob(morphopath+'/*')\n",
    "    frames=0\n",
    "    for f in files:\n",
    "        frames = frames+1\n",
    "    mosift_descriptors = []\n",
    "\n",
    "    for i in range(1, frames-1, interval):\n",
    "        #try:\n",
    "        j=i+1\n",
    "        print(i)\n",
    "        #frame = cv2.imread(morphopath+'/frame%d'%i,cv2.IMREAD_UNCHANGED)\n",
    "        frame = cv.imread(morphopath+'/frame%d.jpg'%i,1)\n",
    "        frame=cv.normalize(frame, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "        next_frame = cv.imread(morphopath+'/frame%d.jpg'%j,1)\n",
    "        next_frame=cv.normalize(next_frame, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "        keypoints, descriptors = gen_sift_features(frame)\n",
    "        keypoints_xy = keypoints_to_coordinates(keypoints)\n",
    "        keypoints_xy = np.float32(np.array(keypoints_xy)[:, np.newaxis, :])\n",
    "        p1, st, err = cv.calcOpticalFlowPyrLK(frame, next_frame, keypoints_xy, None, **lk_params)\n",
    "        sm_keypoints_xy, sm_keypoints, sm_descriptors = has_sufficient_motion(keypoints_xy, keypoints, descriptors, p1, lambd)\n",
    "\n",
    "        for j in range(len(sm_keypoints)):\n",
    "            hof = np.array(gen_hof(sm_keypoints_xy[j][0], sm_keypoints_xy[j][1], frame, next_frame))\n",
    "            mosift_descriptors.append(list(np.concatenate((sm_descriptors[j], hof))))\n",
    "        #except:\n",
    "            #print('Exception in '+video_path+', frame '+str(i))\n",
    "\n",
    "    random_mosift_descriptors = random.sample(mosift_descriptors, k=int(len(mosift_descriptors)*sample_size))\n",
    "\n",
    "    return random_mosift_descriptors\n",
    "\n",
    "\n",
    "def run_feature_extractor(morphopath, output_path,video_name, lambd, interval, sample_size):\n",
    "    \n",
    "    df_mosift_features = pd.DataFrame(gen_mosift_features(morphopath, lambd, interval, sample_size))\n",
    "    print(df_mosift_features)\n",
    "    df_mosift_features.to_csv(output_path+'/'+video_name[13:-4]+\".csv\", mode='a', header=False, index=False)\n",
    "\n",
    "#run_feature_extractor('morphologicallyopenedframes','siftoutput',video_name,0.85,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DELL\\\\ViolenceDetection'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final upto extracting descriptors and stroing them in \"siftoutput\" folder as .csv files.\n",
    "def storeDescriptors(videopath):\n",
    "    videos = glob.glob(videopath+'/*')\n",
    "    for video in videos:\n",
    "        #video=video[13:]\n",
    "        print(video)\n",
    "        preprocess(video)\n",
    "        run_feature_extractor('morphologicallyopenedframes','siftoutput',video,0.85,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def bagOfVisualWords(descriptorspath,noofclusters):\n",
    "    descriptors = glob.glob(descriptorspath+'/*')\n",
    "    maindataframe=pd.DataFrame()\n",
    "    for descriptor in descriptors:\n",
    "        df=pd.read_csv(descriptor,header=None)\n",
    "        maindataframe=maindataframe.append(df)\n",
    "        print(df.shape)\n",
    "    print(maindataframe.shape)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters = noofclusters).fit(maindataframe)\n",
    "    \n",
    "    return kmeans\n",
    "           \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "numberofclusters=200 \n",
    "def featureExtractor(descriptorspath,numberofclusters):\n",
    "    descriptors = glob.glob(descriptorspath+'/*')\n",
    "    trainfeatures=np.empty(shape=[0, 200])\n",
    "    for descriptor in descriptors:\n",
    "        \n",
    "        df=pd.read_csv(descriptor,header=None)\n",
    "        print(df.shape)\n",
    "        histogram=kmeans.predict(df)\n",
    "        \n",
    "        featurevector=np.zeros(numberofclusters,)\n",
    "        for i in range(0,len(histogram)):\n",
    "            featurevector[histogram[i]]=featurevector[histogram[i]]+1\n",
    "        #print(featurevector)\n",
    "        trainfeatures=np.vstack([trainfeatures, featurevector])    \n",
    "    \n",
    "    return trainfeatures\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samplefights\\fi1_xvid.avi\n",
      "25.0\n",
      "25.0\n",
      "[[0 1 0]\n",
      " [1 1 1]\n",
      " [0 1 0]]\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "        0      1      2      3     4     5     6     7      8      9    ...  \\\n",
      "0     128.0   25.0    0.0    2.0  19.0   5.0   5.0  44.0   51.0    7.0  ...   \n",
      "1      31.0   55.0    1.0    0.0   0.0   0.0   0.0   0.0   57.0  121.0  ...   \n",
      "2      12.0    2.0    0.0    0.0   0.0   0.0   0.0   0.0  101.0   31.0  ...   \n",
      "3       0.0    1.0    2.0   13.0  22.0  54.0  14.0   0.0    2.0    0.0  ...   \n",
      "4      40.0   16.0   67.0   57.0   2.0   0.0  11.0  67.0   10.0   19.0  ...   \n",
      "...     ...    ...    ...    ...   ...   ...   ...   ...    ...    ...  ...   \n",
      "4618   42.0  107.0    7.0    0.0   0.0   0.0   1.0  10.0   23.0   51.0  ...   \n",
      "4619    1.0    3.0   96.0  124.0  16.0   0.0   8.0  11.0   16.0    2.0  ...   \n",
      "4620    5.0    0.0    0.0    0.0   0.0   0.0   0.0   4.0  115.0    0.0  ...   \n",
      "4621   11.0   58.0  130.0   27.0   0.0   0.0   0.0   0.0   92.0  122.0  ...   \n",
      "4622   25.0   14.0   95.0  101.0  20.0   0.0   0.0   9.0    2.0    0.0  ...   \n",
      "\n",
      "      246  247  248  249   250  251  252  253  254  255  \n",
      "0     0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.0  0.0  0.0  0.0   3.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...   ...  ...  ...  ...   ...  ...  ...  ...  ...  ...  \n",
      "4618  0.0  0.0  0.0  0.0   9.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4619  0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4620  0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4621  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4622  0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[4623 rows x 256 columns]\n",
      "samplefights\\newfi30.avi\n",
      "25.0\n",
      "25.0\n",
      "[[0 1 0]\n",
      " [1 1 1]\n",
      " [0 1 0]]\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "        0     1      2      3     4     5     6     7      8      9    ...  \\\n",
      "0      74.0  79.0   39.0    4.0   1.0   0.0   0.0   8.0   14.0   59.0  ...   \n",
      "1       0.0   4.0   56.0   79.0  76.0   2.0   0.0   0.0   48.0   99.0  ...   \n",
      "2      44.0   2.0    4.0   18.0  22.0   3.0   2.0  27.0   50.0    3.0  ...   \n",
      "3      88.0   4.0    4.0   14.0  12.0   5.0   3.0  57.0   16.0    1.0  ...   \n",
      "4       2.0  35.0   69.0    0.0   0.0   2.0  40.0   9.0    4.0   39.0  ...   \n",
      "...     ...   ...    ...    ...   ...   ...   ...   ...    ...    ...  ...   \n",
      "33246   5.0   0.0    0.0    3.0  65.0  11.0   0.0   5.0   19.0    2.0  ...   \n",
      "33247   3.0  70.0  111.0    9.0   8.0   6.0   2.0   1.0   20.0  119.0  ...   \n",
      "33248   7.0   7.0   32.0   28.0   3.0   2.0   9.0   7.0    3.0    6.0  ...   \n",
      "33249   9.0   9.0   10.0  129.0  60.0  10.0   4.0   1.0  129.0   80.0  ...   \n",
      "33250  18.0  15.0    6.0    4.0   5.0   2.0   1.0   2.0    5.0    2.0  ...   \n",
      "\n",
      "       246  247  248  249   250  251  252  253  254  255  \n",
      "0      0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1      0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2      0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3      0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4      0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...    ...  ...  ...  ...   ...  ...  ...  ...  ...  ...  \n",
      "33246  0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "33247  0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "33248  0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "33249  0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "33250  0.0  0.0  0.0  0.0  16.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[33251 rows x 256 columns]\n",
      "samplefights\\newfi99.avi\n",
      "29.97002997002997\n",
      "29.97002997002997\n",
      "[[0 1 0]\n",
      " [1 1 1]\n",
      " [0 1 0]]\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-f2fe21406885>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstoreDescriptors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'samplefights'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-61-03ca90828429>\u001b[0m in \u001b[0;36mstoreDescriptors\u001b[1;34m(videopath)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mrun_feature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'morphologicallyopenedframes'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'siftoutput'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.85\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-59-9c00f6bd0e21>\u001b[0m in \u001b[0;36mrun_feature_extractor\u001b[1;34m(morphopath, output_path, video_name, lambd, interval, sample_size)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_feature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmorphopath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mdf_mosift_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_mosift_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmorphopath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_mosift_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mdf_mosift_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-9c00f6bd0e21>\u001b[0m in \u001b[0;36mgen_mosift_features\u001b[1;34m(morphopath, lambd, interval, sample_size)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msm_keypoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mhof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_hof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msm_keypoints_xy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msm_keypoints_xy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mmosift_descriptors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msm_descriptors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m#except:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-57-c31a98c7b4ec>\u001b[0m in \u001b[0;36mgen_hof\u001b[1;34m(x, y, frame, next_frame)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mneighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_neighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mneighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalcOpticalFlowPyrLK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlk_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "storeDescriptors('samplefights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "[[0 1 0]\n",
      " [1 1 1]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storeDescriptors('samplenonfig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siftoutput\\a1.csv\n",
      "siftoutput\\a15.csv\n",
      "siftoutput\\a29.csv\n",
      "siftoutput\\fi1_xvid.csv\n",
      "siftoutput\\newfi30.csv\n",
      "siftoutput\\newfi99.csv\n"
     ]
    }
   ],
   "source": [
    "videos = glob.glob('siftoutput/*')\n",
    "for video in videos:\n",
    "    print(video)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13429, 256)\n",
      "(7325, 256)\n",
      "(7887, 256)\n",
      "(3813, 256)\n",
      "(29794, 256)\n",
      "(13908, 256)\n",
      "(76156, 256)\n"
     ]
    }
   ],
   "source": [
    "kmeans=bagOfVisualWords('siftoutput',200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13429, 256)\n",
      "(7325, 256)\n",
      "(7887, 256)\n",
      "(3813, 256)\n",
      "(29794, 256)\n",
      "(13908, 256)\n",
      "(6, 200)\n"
     ]
    }
   ],
   "source": [
    "trainset=featureExtractor('siftoutput',200)\n",
    "print(trainset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filltargetvariable():\n",
    "    videos = glob.glob('samplenonfig/*')\n",
    "    nonfightcount=0\n",
    "    for video in videos:\n",
    "        nonfightcount=nonfightcount+1\n",
    "    videos = glob.glob('samplefights/*')\n",
    "    fightcount=0\n",
    "    for video in videos:\n",
    "        fightcount=fightcount+1\n",
    "    target1=np.zeros(nonfightcount)\n",
    "\n",
    "    target2=np.ones(fightcount)\n",
    "    target= np.append(target1,target2)\n",
    "    return target\n",
    "\n",
    "target=filltargetvariable()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.3.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from xgboost) (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from xgboost) (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# define data_dmatrix\n",
    "#data_dmatrix = xgb.DMatrix(data=trainset,label=target)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainset, target, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:33:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=20, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.2, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=1, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=20, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# declare parameters\n",
    "params = {\n",
    "            'objective':'binary:logistic',\n",
    "            'max_depth': 2,\n",
    "            'alpha': 20,\n",
    "            'learning_rate': 0.2,\n",
    "            'n_estimators':1\n",
    "        }\n",
    "            \n",
    "            \n",
    "            \n",
    "# instantiate the classifier \n",
    "xgb_clf = XGBClassifier(**params)\n",
    "\n",
    "\n",
    "\n",
    "# fit the classifier to the training data\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# # check accuracy score\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# print('SVM model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "# print(y_test)\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model accuracy score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# check accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('XGBoost model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n",
      "[[7.800e+01 6.200e+01 1.800e+01 4.700e+01 1.800e+01 2.600e+01 2.200e+01\n",
      "  0.000e+00 7.000e+00 3.100e+01 2.500e+01 9.000e+00 6.000e+00 2.600e+01\n",
      "  4.470e+02 1.200e+01 7.600e+01 7.000e+00 7.000e+00 1.100e+02 1.710e+02\n",
      "  2.900e+01 2.600e+01 2.000e+01 7.000e+00 1.900e+01 9.000e+00 9.800e+01\n",
      "  6.600e+01 1.400e+01 2.000e+01 9.000e+00 2.030e+02 0.000e+00 5.000e+01\n",
      "  5.000e+00 1.900e+01 2.000e+01 2.600e+01 2.900e+01 2.500e+01 6.000e+00\n",
      "  2.400e+01 3.600e+01 1.600e+02 4.800e+01 3.000e+00 2.100e+01 2.600e+01\n",
      "  2.500e+01 2.800e+01 6.600e+01 5.500e+01 2.000e+00 1.800e+01 2.700e+01\n",
      "  9.400e+01 6.200e+01 6.600e+01 4.500e+01 3.200e+01 1.500e+01 7.000e+01\n",
      "  8.000e+00 2.300e+01 2.500e+01 3.880e+02 9.000e+00 2.700e+01 4.900e+01\n",
      "  1.000e+00 1.200e+01 1.000e+00 1.640e+02 6.900e+01 5.000e+00 9.000e+00\n",
      "  1.000e+00 1.000e+00 4.300e+01 1.800e+01 5.000e+00 2.000e+01 1.200e+01\n",
      "  1.300e+01 4.200e+01 2.000e+00 1.049e+03 4.000e+00 7.000e+00 3.100e+01\n",
      "  6.000e+00 7.100e+01 8.500e+01 5.700e+01 2.900e+01 6.000e+00 3.700e+01\n",
      "  5.000e+00 1.100e+01 4.000e+00 4.000e+00 1.000e+01 4.700e+01 1.200e+01\n",
      "  9.000e+00 3.000e+00 1.100e+01 1.000e+01 9.000e+00 3.000e+00 1.000e+01\n",
      "  5.200e+01 1.100e+01 0.000e+00 5.500e+01 7.900e+01 5.000e+00 5.000e+00\n",
      "  2.100e+01 8.500e+01 4.000e+00 1.200e+01 1.800e+01 1.100e+01 1.050e+02\n",
      "  3.000e+01 6.000e+00 5.400e+01 4.000e+00 8.900e+01 3.100e+01 0.000e+00\n",
      "  6.900e+01 2.800e+01 2.300e+01 3.000e+00 1.000e+01 4.800e+01 5.000e+00\n",
      "  2.300e+01 2.000e+01 3.000e+01 0.000e+00 1.100e+01 3.500e+01 1.000e+01\n",
      "  4.300e+01 1.000e+01 6.000e+00 4.000e+00 2.000e+00 3.700e+01 1.060e+02\n",
      "  1.200e+01 1.100e+01 1.000e+00 1.700e+01 4.900e+01 1.300e+01 0.000e+00\n",
      "  8.000e+00 1.700e+01 7.100e+01 1.100e+01 2.000e+01 1.000e+00 1.800e+01\n",
      "  7.000e+00 1.400e+01 2.000e+00 2.200e+01 5.300e+01 6.000e+01 4.200e+01\n",
      "  5.000e+01 3.500e+01 6.300e+01 1.210e+02 6.300e+01 0.000e+00 1.000e+01\n",
      "  3.000e+01 1.000e+00 9.400e+01 7.500e+01 3.700e+01 7.600e+01 1.900e+01\n",
      "  5.000e+00 0.000e+00 2.000e+00 8.000e+01 7.400e+01 7.000e+00 6.000e+00\n",
      "  1.200e+01 3.500e+01 1.700e+01 2.100e+01]\n",
      " [5.300e+01 4.500e+01 2.200e+01 3.400e+01 2.000e+01 2.100e+01 3.700e+01\n",
      "  9.000e+00 2.100e+01 1.900e+01 2.600e+01 2.200e+01 3.000e+01 2.300e+01\n",
      "  3.130e+02 1.800e+01 4.900e+01 2.300e+01 1.700e+01 1.030e+02 1.100e+02\n",
      "  4.200e+01 1.600e+01 3.800e+01 1.600e+01 1.800e+01 1.800e+01 6.700e+01\n",
      "  4.500e+01 2.000e+01 1.300e+01 1.600e+01 1.520e+02 1.700e+01 4.000e+01\n",
      "  2.200e+01 3.600e+01 1.900e+01 3.700e+01 2.100e+01 2.700e+01 2.900e+01\n",
      "  3.300e+01 2.100e+01 8.800e+01 4.300e+01 7.000e+00 1.200e+01 2.300e+01\n",
      "  2.600e+01 2.200e+01 6.100e+01 4.400e+01 3.300e+01 2.000e+01 2.500e+01\n",
      "  5.900e+01 5.700e+01 3.900e+01 5.300e+01 2.900e+01 2.700e+01 4.600e+01\n",
      "  1.400e+01 3.400e+01 1.900e+01 2.890e+02 1.100e+01 3.700e+01 4.000e+01\n",
      "  1.000e+01 1.600e+01 1.300e+01 1.240e+02 6.300e+01 2.200e+01 1.200e+01\n",
      "  1.400e+01 7.000e+00 3.600e+01 1.600e+01 2.400e+01 2.900e+01 1.600e+01\n",
      "  2.400e+01 3.200e+01 2.500e+01 7.590e+02 1.600e+01 1.200e+01 3.000e+01\n",
      "  2.900e+01 7.100e+01 8.300e+01 4.500e+01 2.700e+01 2.900e+01 1.700e+01\n",
      "  1.100e+01 1.300e+01 2.100e+01 9.000e+00 4.000e+01 2.100e+01 2.700e+01\n",
      "  2.100e+01 1.200e+01 3.200e+01 3.100e+01 1.800e+01 1.700e+01 2.000e+01\n",
      "  3.200e+01 2.500e+01 1.800e+01 4.700e+01 7.100e+01 2.800e+01 2.300e+01\n",
      "  2.300e+01 6.300e+01 1.500e+01 2.900e+01 1.500e+01 6.000e+00 5.300e+01\n",
      "  2.900e+01 1.600e+01 2.700e+01 3.400e+01 6.700e+01 2.400e+01 1.000e+00\n",
      "  6.000e+01 2.600e+01 1.600e+01 2.000e+01 3.200e+01 2.700e+01 2.100e+01\n",
      "  2.700e+01 2.900e+01 2.500e+01 1.000e+01 2.400e+01 4.300e+01 1.700e+01\n",
      "  3.200e+01 1.700e+01 2.600e+01 4.000e+01 7.000e+00 3.100e+01 6.000e+01\n",
      "  1.000e+01 2.100e+01 1.300e+01 2.000e+01 3.600e+01 1.300e+01 9.000e+00\n",
      "  2.400e+01 2.500e+01 4.100e+01 1.900e+01 2.900e+01 7.000e+00 2.100e+01\n",
      "  8.000e+00 2.300e+01 1.500e+01 1.300e+01 3.400e+01 4.200e+01 3.700e+01\n",
      "  3.900e+01 2.200e+01 4.600e+01 6.300e+01 4.500e+01 6.000e+00 3.400e+01\n",
      "  1.700e+01 7.000e+00 6.900e+01 4.700e+01 3.400e+01 2.600e+01 2.400e+01\n",
      "  2.200e+01 1.800e+01 1.500e+01 5.800e+01 3.400e+01 1.700e+01 2.400e+01\n",
      "  2.600e+01 5.000e+01 2.700e+01 2.900e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

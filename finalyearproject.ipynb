{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "def FrameCapture(path,skipfactor=3): \n",
    "    #clearing extracted frames\n",
    "    files = glob.glob('extractedframes/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "        \n",
    "    # Path to video file \n",
    "    vidObj = cv2.VideoCapture(path) \n",
    "    fps = vidObj.get(cv2.CAP_PROP_FPS)\n",
    "    print(fps)\n",
    "    vidObj.set(cv2.CAP_PROP_FPS, 30)\n",
    "    fps = vidObj.get(cv2.CAP_PROP_FPS)\n",
    "    print(fps)\n",
    "    # Used as counter variable \n",
    "    count = 0\n",
    "    ind = 0\n",
    "  \n",
    "    # checks whether frames were extracted \n",
    "    success = 1\n",
    "    listOfImages = []\n",
    "    while success: \n",
    "  \n",
    "        # vidObj object calls read \n",
    "        # function extract frames \n",
    "        success, image = vidObj.read()\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Saves the frames with frame-count \n",
    "        if(count%skipfactor==0):\n",
    "            listOfImages.append(image)\n",
    "            \n",
    "            #cv2.imwrite(\"extractedframes/frame%d.jpg\" %ind, image)\n",
    "            #cv2.imshow('frame%d.jpg'%ind,image)\n",
    "            \n",
    "            ind += 1\n",
    "        count += 1\n",
    "        type(image)\n",
    "    return listOfImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListGrayscaleFrameArrays(listOfFrames):\n",
    "    listOfFrameArray=[]\n",
    "    listOfFrames.pop()\n",
    "    \n",
    "    for ind,frame  in enumerate(listOfFrames):\n",
    "        #converts RBG image to Gray scale and returns as numpy 2D array\n",
    "        ff= frame.copy()\n",
    "        gray = cv2.cvtColor(ff, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "#         print(gray.shape)\n",
    "#         scale_percent = 60 # percent of original size\n",
    "#         width = int(1000)\n",
    "#         height = int(1000)\n",
    "#         dim = (width, height)\n",
    "#         # resize image\n",
    "#         resized = cv2.resize(gray, dim, interpolation = cv2.INTER_AREA)\n",
    "        cv2.imwrite(\"grayframes/frame%d.jpg\" %ind, gray)\n",
    "        #using PIL\n",
    "        #grayscalearray = np.array(Image.fromarray(frame).convert('L'))\n",
    "        grayscalearray = np.array(gray)\n",
    "        \n",
    "        listOfFrameArray.append(grayscalearray)\n",
    "        \n",
    "    return listOfFrameArray\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def StoreFrames(path,skipfactor=2):\n",
    "    #extracted features stores all gray frames of a  video individually for further processing\n",
    "    #clear extracted frames folder first\n",
    "    files = glob.glob('extractedframes/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    FrameCapture(path,skipfactor)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A  video is converted to a numpy array\n",
    "def ConvertVideoToGrayscaleArray(path):\n",
    "    listofImages = FrameCapture(path,2)\n",
    "\n",
    "    GrayScaleList= ListGrayscaleFrameArrays(listofImages)\n",
    "    \n",
    "    ArrayofGrayScaleArray = np.array(GrayScaleList)\n",
    "    \n",
    "    #print(ArrayofGrayScaleArray.shape)\n",
    "    return ArrayofGrayScaleArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movementfiltering\n",
    "\n",
    "#stores binarized list of frames in jpg format \n",
    "def BinarizeGrayscaleArray(ArrayofGrayScaleArray,path,threshold=120):\n",
    "    files = glob.glob('binaryframes/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    for i in range(1,ArrayofGrayScaleArray.shape[0]):\n",
    "        binaryImage=abs(ArrayofGrayScaleArray[i]-ArrayofGrayScaleArray[i-1])\n",
    "        data = Image.fromarray(binaryImage)\n",
    "        data.save('temporalderivatives/'+'frame%d.jpg'%i)\n",
    "        #Binarization\n",
    "        binaryImage[binaryImage > threshold] = 255\n",
    "        binaryImage[binaryImage <= threshold] = 0  \n",
    "        data = Image.fromarray(binaryImage) \n",
    "        data.save(path+'/'+'frame%d.jpg'%i)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DELL\\\\ViolenceDetection'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erodeBinaryFrames(binaryframespath,erodedframespath):\n",
    "    erosionkernel = np.ones((4,4), np.uint8)\n",
    "    erosionkernel[0][0]=0\n",
    "    erosionkernel[0][3]=0\n",
    "    erosionkernel[3][0]=0\n",
    "    erosionkernel[3][3]=0\n",
    "    print(erosionkernel)\n",
    "\n",
    "    # Taking a matrix of size 5 as the kernel \n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    kernel[0][0]=0\n",
    "    kernel[0][2]=0\n",
    "    kernel[2][0]=0\n",
    "    kernel[2][2]=0\n",
    "    print(kernel)\n",
    "    # The first parameter is the original image, \n",
    "    # kernel is the matrix with which image is  \n",
    "    # convolved and third parameter is the number  \n",
    "    # of iterations, which will determine how much  \n",
    "    # you want to erode/dilate a given image.\n",
    "    files = glob.glob(erodedframespath+'/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    files = glob.glob(binaryframespath+'/*')\n",
    "    for ind,f in enumerate(files):\n",
    "        img = cv2.imread(f, 0) \n",
    "        img_erosion = cv2.erode(img, kernel, iterations=1) \n",
    "        #img_dilation = cv2.dilate(img, kernel, iterations=1)\n",
    "        cv2.imwrite(erodedframespath+\"/frame%d.jpg\" %ind,img_erosion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n",
      "25.0\n",
      "[[0 1 1 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 1 1 0]]\n",
      "[[0 1 0]\n",
      " [1 1 1]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "def preProcess(videopath):\n",
    "    #A  video is converted to a numpy array\n",
    "    ArrayofGrayScaleArray= ConvertVideoToGrayscaleArray(videopath)\n",
    "    BinarizeGrayscaleArray(ArrayofGrayScaleArray,'binaryframes')\n",
    "    erodeBinaryFrames(\"binaryframes\",\"morphologicallyopenedframes\")\n",
    "#upto morphological opening\n",
    "preProcess('samplefights/newfi30.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# progress: 1/1\n",
      "siftvideo/fi1_xvid.avi\n"
     ]
    }
   ],
   "source": [
    "#SIFT\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "# params for ShimTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# params for Lucas Kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "\n",
    "def capture_frame(video_path, i):\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    cap.set(1, i)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    return ret, frame\n",
    "\n",
    "\n",
    "def count_frames(video_path):\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def gen_sift_features(frame):\n",
    "    sift = cv.SIFT()\n",
    "    keypoints, descriptors = sift.detectAndCompute(frame, None)\n",
    "\n",
    "    return keypoints, descriptors\n",
    "\n",
    "\n",
    "def keypoints_to_coordinates(keypoints):\n",
    "    keypoints_xy = []\n",
    "\n",
    "    for kp in keypoints:\n",
    "        keypoints_xy.append([kp.pt[0], kp.pt[1]])\n",
    "\n",
    "    return keypoints_xy\n",
    "\n",
    "\n",
    "def has_sufficient_motion(keypoints_xy, keypoints, descriptors, p1, lambd):\n",
    "    sm_keypoints_xy = []\n",
    "    sm_keypoints = []\n",
    "    sm_descriptors = []\n",
    "\n",
    "    for i in range(len(keypoints)):\n",
    "        distance_x = keypoints_xy[i].T[0] - p1[i].T[0]\n",
    "        distance_y = keypoints_xy[i].T[1] - p1[i].T[1]\n",
    "\n",
    "        if distance_x > lambd or distance_y > lambd:\n",
    "            sm_keypoints_xy.append([int(keypoints_xy[i].T[0]), int(keypoints_xy[i].T[1])])\n",
    "            sm_keypoints.append(keypoints[i])\n",
    "            sm_descriptors.append(descriptors[i])\n",
    "\n",
    "    return sm_keypoints_xy, sm_keypoints, sm_descriptors\n",
    "\n",
    "\n",
    "def gen_hof(x, y, frame, next_frame):\n",
    "    hof = []\n",
    "    histogram = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    neighbors = util.gen_neighbors(x, y)\n",
    "    neighbors = np.float32(np.array(neighbors)[:, np.newaxis, :])\n",
    "    p1, st, err = cv.calcOpticalFlowPyrLK(frame, next_frame, neighbors, None, **lk_params)\n",
    "\n",
    "    for i in range(len(p1)):\n",
    "        direction = np.arctan(p1[i].T[0]/p1[i].T[1])\n",
    "        histogram = util.gen_arc_histogram(direction, histogram)\n",
    "        if i in util.cells:\n",
    "            hof += histogram\n",
    "            histogram = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    return hof\n",
    "\n",
    "\n",
    "def gen_mosift_features(video_path, lambd, interval, sample_size):\n",
    "    frames = count_frames(video_path)\n",
    "    mosift_descriptors = []\n",
    "\n",
    "    for i in range(1, frames-1, interval):\n",
    "        #try:\n",
    "        ret, frame = capture_frame(video_path, i)\n",
    "        ret, next_frame = capture_frame(video_path, i+1)\n",
    "        keypoints, descriptors = gen_sift_features(frame)\n",
    "        print('gen_sift_features')\n",
    "        keypoints_xy = keypoints_to_coordinates(keypoints)\n",
    "        keypoints_xy = np.float32(np.array(keypoints_xy)[:, np.newaxis, :])\n",
    "        p1, st, err = cv.calcOpticalFlowPyrLK(frame, next_frame, keypoints_xy, None, **lk_params)\n",
    "        sm_keypoints_xy, sm_keypoints, sm_descriptors = has_sufficient_motion(keypoints_xy, keypoints, descriptors, p1, lambd)\n",
    "\n",
    "        for j in range(len(sm_keypoints)):\n",
    "            hof = np.array(gen_hof(sm_keypoints_xy[j][0], sm_keypoints_xy[j][1], frame, next_frame))\n",
    "            mosift_descriptors.append(list(np.concatenate((sm_descriptors[j], hof))))\n",
    "        #except:\n",
    "            #print('Exception in '+video_path+', frame '+str(i))\n",
    "\n",
    "    random_mosift_descriptors = random.sample(mosift_descriptors, k=int(len(mosift_descriptors)*sample_size))\n",
    "\n",
    "    return random_mosift_descriptors\n",
    "\n",
    "\n",
    "def run_feature_extractor(input_path, output_path, lambd, interval, sample_size):\n",
    "    listing = os.listdir(input_path)\n",
    "    progress_count = 0\n",
    "    for video_name in listing:\n",
    "        progress_count += 1\n",
    "        print(\"# progress: \"+str(progress_count)+'/'+str(len(listing)))\n",
    "        video_path = input_path+'/'+ video_name\n",
    "        print(video_path)\n",
    "        df_mosift_features = pd.DataFrame(gen_mosift_features(video_path, lambd, interval, sample_size))\n",
    "        print(df_mosift_features)\n",
    "        df_mosift_features.to_csv(output_path+video_name[:-4]+\".csv\", mode='a', header=False, index=False)\n",
    "\n",
    "run_feature_extractor('siftvideo','siftoutput',0.7,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement opencv-python==3.4.2.17 (from versions: 3.4.8.29, 3.4.9.31, 3.4.9.33, 3.4.10.35, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 4.1.2.30, 4.2.0.32, 4.2.0.34, 4.3.0.36, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48)\n",
      "ERROR: No matching distribution found for opencv-python==3.4.2.17\n",
      "WARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python==3.4.2.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-util\n",
      "  Downloading python_util-1.2.1-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: python-util\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed python-util-1.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
